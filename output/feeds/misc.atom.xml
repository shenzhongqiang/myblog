<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>强哥的世界 - misc</title><link href="http://www.shenzhongqiang.com/" rel="alternate"></link><link href="http://www.shenzhongqiang.com/feeds/misc.atom.xml" rel="self"></link><id>http://www.shenzhongqiang.com/</id><updated>2018-06-23T00:00:00+08:00</updated><subtitle>技术 | 生活 | 摄影</subtitle><entry><title>10行代码识别二维码</title><link href="http://www.shenzhongqiang.com/recognize-qr-code.html" rel="alternate"></link><published>2018-06-23T00:00:00+08:00</published><updated>2018-06-23T00:00:00+08:00</updated><author><name>Zhongqiang Shen</name></author><id>tag:www.shenzhongqiang.com,2018-06-23:/recognize-qr-code.html</id><summary type="html">&lt;p&gt;二维码现在已深入到我们生活的方方面面了，手机支付、微信加好友、app下载、电子票务等方方面面都有它的身影 …&lt;/p&gt;</summary><content type="html">&lt;p&gt;二维码现在已深入到我们生活的方方面面了，手机支付、微信加好友、app下载、电子票务等方方面面都有它的身影。最近坐地铁又推出了扫二维码进出站。&lt;/p&gt;
&lt;p&gt;最近一段时间，上海的很多地铁检票机器都装上了像下面这样的二维码扫描器&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.shenzhongqiang.com/images/v2-acebb23eaff588dc3f0844726d0605c0_r.jpg"&gt;&lt;/p&gt;
&lt;p&gt;只需打开手机app上的二维码，对准扫描窗口扫一扫，就可以进站，到站后再扫一扫，就可以出站并自动扣款。&lt;/p&gt;
&lt;p&gt;今天我们就来用Python实现一个简单的识别二维码的程序。&lt;/p&gt;
&lt;h4&gt;准备工作&lt;/h4&gt;
&lt;p&gt;识别二维码需要用到zbar，首先安装libzbar0，以Ubuntu为例&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt-get install libzbar0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;接着安装pyzbar和opencv&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install pyzbar
pip install opencv-python
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;代码实现&lt;/h4&gt;
&lt;p&gt;接下来是我们的代码实现部分了，可以看到代码非常简单。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# -*- coding: utf-8 -*-&lt;/span&gt;
&lt;span class="c1"&gt;# filename: read_qrcode.py&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt; 
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pyzbar.pyzbar&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;decode&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;cv2&lt;/span&gt; 

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Usage: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt; &amp;lt;image file&amp;gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;filepath&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cv2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;imread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filepath&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 读入图片&lt;/span&gt;
&lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 解码二维码&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="c1"&gt;# 打印解码的数据&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;测试&lt;/h4&gt;
&lt;p&gt;我们拿下面的二维码来测试一下（因为知乎会自动转换二维码，这里不得已把图片作了下分割）&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.shenzhongqiang.com/images/v2-6c12c28182327fd821763cda91ed22a9_b.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.shenzhongqiang.com/images/v2-40192faa7a28708c254571598c3f9961_b.jpg"&gt;&lt;/p&gt;
&lt;p&gt;运行上面的read_qrcode.py，可以看到如下的结果：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;QRCODE 欢迎关注“Python与数据分析”专栏
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;：）&lt;/p&gt;
&lt;p&gt;本文已更新微信同名公众号【Python与数据分析】，欢迎关注~&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.shenzhongqiang.com/images/v2-e9b0b9b9584ccdd3ff4c96b7ecfd8a56_r.jpg"&gt;&lt;/p&gt;</content><category term="misc"></category></entry><entry><title>一款超酷的Chrome插件</title><link href="http://www.shenzhongqiang.com/cool-chrome-extensions-momentum.html" rel="alternate"></link><published>2018-06-23T00:00:00+08:00</published><updated>2018-06-23T00:00:00+08:00</updated><author><name>Zhongqiang Shen</name></author><id>tag:www.shenzhongqiang.com,2018-06-23:/cool-chrome-extensions-momentum.html</id><summary type="html">&lt;p&gt;最近发现一款超酷的Chrome插件，名叫Momentum。每次打开一个新的Tab页面，看着Chrome单调的默认页面，难免让人觉得乏味 …&lt;/p&gt;</summary><content type="html">&lt;p&gt;最近发现一款超酷的Chrome插件，名叫Momentum。每次打开一个新的Tab页面，看着Chrome单调的默认页面，难免让人觉得乏味。装上了Momentum后，打开新的Tab页面，展现在你眼前的是一张漂亮的风景照片，不由让人觉得耳目一新，心情也随之振奋起来。&lt;/p&gt;
&lt;p&gt;Momentum每天换一张图，装上了Momentum的Chrome的新页面长这样&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.shenzhongqiang.com/images/v2-7f16b6ae262f5cf2c923883ca0167779_r.jpg"&gt;&lt;/p&gt;
&lt;p&gt;除了漂亮的背景图片、时间显示，这款插件还提供了天气预报、收藏夹、待办事项的功能，像下面&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.shenzhongqiang.com/images/v2-0343afc26e38eff1a405792cb662d241_b.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.shenzhongqiang.com/images/v2-f33d26707fc672c409c444ee61b4618e_b.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.shenzhongqiang.com/images/v2-490c725d5f2f168fcb096c40366442e1_b.jpg"&gt;&lt;/p&gt;
&lt;p&gt;自从装上了这款插件，感觉工作效率也比以前有了提升。&lt;/p&gt;
&lt;p&gt;Momentum的官方地址是&lt;a href="http://link.zhihu.com/?target=https%3A//momentumdash.com/"&gt;Momentum Dashboard&lt;/a&gt;。通过Chrome应用商店安装这款插件需要科学上网。&lt;/p&gt;
&lt;p&gt;本文已更新微信同名公众号【Python与数据分析】，欢迎关注~&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.shenzhongqiang.com/images/v2-e9b0b9b9584ccdd3ff4c96b7ecfd8a56_r.jpg"&gt;&lt;/p&gt;</content><category term="misc"></category></entry><entry><title>推荐一款提升web开发效率的利器</title><link href="http://www.shenzhongqiang.com/chrome-json-view.html" rel="alternate"></link><published>2018-05-30T00:00:00+08:00</published><updated>2018-05-30T00:00:00+08:00</updated><author><name>Zhongqiang Shen</name></author><id>tag:www.shenzhongqiang.com,2018-05-30:/chrome-json-view.html</id><summary type="html">&lt;p&gt;今天要推荐的是一款Chrome插件，名叫JSONView。&lt;/p&gt;
&lt;p&gt;在做web开发的时候，api接口一般是返回json格式的。而在调试api接口的时候 …&lt;/p&gt;</summary><content type="html">&lt;p&gt;今天要推荐的是一款Chrome插件，名叫JSONView。&lt;/p&gt;
&lt;p&gt;在做web开发的时候，api接口一般是返回json格式的。而在调试api接口的时候，我们经常需要在浏览器里查看api的返回结果。&lt;/p&gt;
&lt;p&gt;没有JSONView的时候，Chrome显示的json是这样的&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.shenzhongqiang.com/images/v2-114cd53cd898decf0cd936a1440c7bf9_r.jpg"&gt;&lt;/p&gt;
&lt;p&gt;各种各样的字段密密麻麻挤在一起，看都看不清楚，每次调试起来都非常痛苦。&lt;/p&gt;
&lt;p&gt;有了JSONView之后，Chrome显示的json就变成了这样&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.shenzhongqiang.com/images/v2-c85e25e8e6aadf3f9bcdabcd90fccfaf_r.jpg"&gt;&lt;/p&gt;
&lt;p&gt;一下子清楚了很多有没有？Debug效率大大提升了有没有？安装了这款插件后，心情都变好了呢~&lt;/p&gt;
&lt;p&gt;通过Chrome应用商店安装这款插件需科学上网。&lt;/p&gt;</content><category term="misc"></category></entry><entry><title>Kafka入门简介</title><link href="http://www.shenzhongqiang.com/kafka-intro.html" rel="alternate"></link><published>2018-03-22T00:00:00+08:00</published><updated>2018-03-22T00:00:00+08:00</updated><author><name>Zhongqiang Shen</name></author><id>tag:www.shenzhongqiang.com,2018-03-22:/kafka-intro.html</id><summary type="html">&lt;p&gt;本文简单的介绍下kafka，主要包含以下部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;什么是Kafka&lt;/li&gt;
&lt;li&gt;Kafka的基本概念&lt;/li&gt;
&lt;li&gt;Kafka分布式架构 …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;本文简单的介绍下kafka，主要包含以下部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;什么是Kafka&lt;/li&gt;
&lt;li&gt;Kafka的基本概念&lt;/li&gt;
&lt;li&gt;Kafka分布式架构&lt;/li&gt;
&lt;li&gt;配置单机版Kafka&lt;/li&gt;
&lt;li&gt;实验一：kafka-python实现生产者消费者&lt;/li&gt;
&lt;li&gt;实验二：消费组实现容错性机制&lt;/li&gt;
&lt;li&gt;实验三：offset管理&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;什么是Kafka&lt;/h4&gt;
&lt;p&gt;Kafka是一个分布式流处理系统，流处理系统使它可以像消息队列一样publish或者subscribe消息，分布式提供了容错性，并发处理消息的机制。&lt;/p&gt;
&lt;h4&gt;Kafka的基本概念&lt;/h4&gt;
&lt;p&gt;kafka运行在集群上，集群包含一个或多个服务器。kafka把消息存在topic中，每一条消息包含键值（key），值（value）和时间戳（timestamp）。&lt;/p&gt;
&lt;p&gt;kafka有以下一些基本概念：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Producer &lt;/strong&gt;- 消息生产者，就是向kafka broker发消息的客户端。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Consumer &lt;/strong&gt;- 消息消费者，是消息的使用方，负责消费Kafka服务器上的消息。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Topic &lt;/strong&gt;- 主题，由用户定义并配置在Kafka服务器，用于建立Producer和Consumer之间的订阅关系。生产者发送消息到指定的Topic下，消息者从这个Topic下消费消息。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Partition&lt;/strong&gt; - 消息分区，一个topic可以分为多个 partition，每个
partition是一个有序的队列。partition中的每条消息都会被分配一个有序的
id（offset）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Broker &lt;/strong&gt;- 一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Consumer Group&lt;/strong&gt; - 消费者分组，用于归组同类消费者。每个consumer属于一个特定的consumer group，多个消费者可以共同消息一个Topic下的消息，每个消费者消费其中的部分消息，这些消费者就组成了一个分组，拥有同一个分组名称，通常也被称为消费者集群。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Offset &lt;/strong&gt;- 消息在partition中的偏移量。每一条消息在partition都有唯一的偏移量，消息者可以指定偏移量来指定要消费的消息。&lt;/p&gt;
&lt;h4&gt;Kafka分布式架构&lt;/h4&gt;
&lt;p&gt;&lt;img alt="" src="http://www.shenzhongqiang.com/images/v2-f04083507c2860e62a686c3e868c719a_b.jpg"&gt;&lt;/p&gt;
&lt;p&gt;如上图所示，kafka将topic中的消息存在不同的partition中。如果存在键值（key），消息按照键值（key）做分类存在不同的partiition中，如果不存在键值（key），消息按照轮询（Round Robin）机制存在不同的partition中。默认情况下，键值（key）决定了一条消息会被存在哪个partition中。&lt;/p&gt;
&lt;p&gt;partition中的消息序列是有序的消息序列。kafka在partition使用偏移量（offset）来指定消息的位置。一个topic的一个partition只能被一个consumer group中的一个consumer消费，多个consumer消费同一个partition中的数据是不允许的，但是一个consumer可以消费多个partition中的数据。&lt;/p&gt;
&lt;p&gt;kafka将partition的数据复制到不同的broker，提供了partition数据的备份。每一个partition都有一个broker作为leader，若干个broker作为follower。所有的数据读写都通过leader所在的服务器进行，并且leader在不同broker之间复制数据。&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.shenzhongqiang.com/images/v2-e9b8513d58089eee6a131278ea949502_r.jpg"&gt;&lt;/p&gt;
&lt;p&gt;上图中，对于Partition 0，broker 1是它的leader，broker 2和broker 3是follower。对于Partition 1，broker 2是它的leader，broker 1和broker 3是follower。&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.shenzhongqiang.com/images/v2-a247b3d0f9fc622224f69bbdda1ab933_r.jpg"&gt;&lt;/p&gt;
&lt;p&gt;在上图中，当有Client（也就是Producer）要写入数据到Partition 0时，会写入到leader Broker 1，Broker 1再将数据复制到follower Broker 2和Broker 3。&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.shenzhongqiang.com/images/v2-9f15b48732fb965a8ed0644cc902bd67_r.jpg"&gt;&lt;/p&gt;
&lt;p&gt;在上图中，Client向Partition 1中写入数据时，会写入到Broker 2，因为Broker 2是Partition 1的Leader，然后Broker 2再将数据复制到follower Broker 1和Broker 3中。&lt;/p&gt;
&lt;p&gt;上图中的topic一共有3个partition，对每个partition的读写都由不同的broker处理，因此总的吞吐量得到了提升。&lt;/p&gt;
&lt;h4&gt;配置单机版Kafka&lt;/h4&gt;
&lt;p&gt;这里我们使用kafka 0.10.0.0版本。&lt;/p&gt;
&lt;p&gt;第一步：下载并解压包&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ wget https://archive.apache.org/dist/kafka/0.10.0.0/kafka_2.11-0.10.0.0.tgz
$ tar -xzf kafka_2.11-0.10.0.0.tgz
$ &lt;span class="nb"&gt;cd&lt;/span&gt; kafka_2.11-0.10.0.0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;第二步：启动Kafka&lt;/p&gt;
&lt;p&gt;kafka需要用到zookeeper，所以需要先启动zookeeper。我们这里使用下载包里自带的单机版zookeeper。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ bin/zookeeper-server-start.sh config/zookeeper.properties
&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;2013&lt;/span&gt;-04-22 &lt;span class="m"&gt;15&lt;/span&gt;:01:37,495&lt;span class="o"&gt;]&lt;/span&gt; INFO Reading configuration from: config/zookeeper.properties &lt;span class="o"&gt;(&lt;/span&gt;org.apache.zookeeper.server.quorum.QuorumPeerConfig&lt;span class="o"&gt;)&lt;/span&gt;
...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;然后启动kafka&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ bin/kafka-server-start.sh config/server.properties
&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;2013&lt;/span&gt;-04-22 &lt;span class="m"&gt;15&lt;/span&gt;:01:47,028&lt;span class="o"&gt;]&lt;/span&gt; INFO Verifying properties &lt;span class="o"&gt;(&lt;/span&gt;kafka.utils.VerifiableProperties&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;2013&lt;/span&gt;-04-22 &lt;span class="m"&gt;15&lt;/span&gt;:01:47,051&lt;span class="o"&gt;]&lt;/span&gt; INFO Property socket.send.buffer.bytes is overridden to &lt;span class="m"&gt;1048576&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;kafka.utils.VerifiableProperties&lt;span class="o"&gt;)&lt;/span&gt;
...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;第三步：创建topic&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor &lt;span class="m"&gt;1&lt;/span&gt; --partitions &lt;span class="m"&gt;1&lt;/span&gt; --topic &lt;span class="nb"&gt;test&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;查看创建的topic&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ bin/kafka-topics.sh --list --zookeeper localhost:2181
&lt;span class="nb"&gt;test&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;第四步：向topic中发送消息&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
This is a message
This is another message
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;第五步：从topicc中消费消息&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic &lt;span class="nb"&gt;test&lt;/span&gt; --from-beginning
This is a message
This is another message
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;实验一：kafka-python实现生产者消费者&lt;/h4&gt;
&lt;p&gt;kafka-python是一个python的Kafka客户端，可以用来向kafka的topic发送消息、消费消息。&lt;/p&gt;
&lt;p&gt;这个实验会实现一个producer和一个consumer，producer向kafka发送消息，consumer从topic中消费消息。结构如下图&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.shenzhongqiang.com/images/v2-198d01ebb230395234999a3b8ac07502_r.jpg"&gt;&lt;/p&gt;
&lt;p&gt;producer代码&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# producer.py&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;kafka&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;KafkaProducer&lt;/span&gt;

&lt;span class="n"&gt;producer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;KafkaProducer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bootstrap_servers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;localhost:9092&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;ts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;producer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;send&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;test&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;timestamp_ms&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;producer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flush&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;
    &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;consumer代码&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# consumer.py&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;kafka&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;KafkaConsumer&lt;/span&gt;

&lt;span class="n"&gt;consumer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;KafkaConsumer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;test&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bootstrap_servers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;localhost:9092&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;message&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;message&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;接下来创建test topic&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor &lt;span class="m"&gt;1&lt;/span&gt; --partitions &lt;span class="m"&gt;1&lt;/span&gt; --topic &lt;span class="nb"&gt;test&lt;/span&gt;
Created topic &lt;span class="s2"&gt;&amp;quot;test&amp;quot;&lt;/span&gt;.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;打开两个窗口中，我们在window1中运行producer，如下&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# window1&lt;/span&gt;
$ python producer.py
&lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="m"&gt;2&lt;/span&gt;
&lt;span class="m"&gt;3&lt;/span&gt;
&lt;span class="m"&gt;4&lt;/span&gt;
&lt;span class="m"&gt;5&lt;/span&gt;
...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;在window2中运行consumer，如下&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# window2&lt;/span&gt;
$ python consumer.py
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;128&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512554839806&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;128&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;128&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1439508774, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;129&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512554840827&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;129&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;129&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1515993224&lt;/span&gt;, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;130&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512554841834&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;130&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;130&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;453490213&lt;/span&gt;, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;131&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512554842841&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;131&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;131&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-632119731, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;可以看到window2中的consumer成功的读到了producer写入的数据&lt;/p&gt;
&lt;h4&gt;实验二：消费组实现容错性机制&lt;/h4&gt;
&lt;p&gt;这个实验将展示消费组的容错性的特点。这个实验中将创建一个有2个partition的topic，和2个consumer，这2个consumer共同消费同一个topic中的数据。结构如下所示&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.shenzhongqiang.com/images/v2-c13a7ea159c44df872a5845c3cd3f6c6_r.jpg"&gt;&lt;/p&gt;
&lt;p&gt;producer部分代码和实验一相同，这里不再重复。consumer需要指定所属的consumer group，代码如下&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# consumer.py&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;kafka&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;KafkaConsumer&lt;/span&gt;

&lt;span class="n"&gt;consumer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;KafkaConsumer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;test&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bootstrap_servers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;localhost:9092&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;group_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;testgoup&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;message&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;message&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;接下来我们创建topic，名字test，设置partition数量为2&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 2 --topic test
Created topic &amp;quot;test&amp;quot;.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;打开三个窗口，一个窗口运行producer，还有两个窗口运行consumer。&lt;/p&gt;
&lt;p&gt;运行consumer的两个窗口的输出如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# window1&lt;/span&gt;
$ python consumer.py
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;11&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512556619298&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;15&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;15&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1492440752, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;12&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512556621308&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;17&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;17&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1029407634, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;13&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512556622316&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;18&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;18&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1544755853&lt;/span&gt;, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;14&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512556624326&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;20&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;20&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2130557725&lt;/span&gt;, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
...


&lt;span class="c1"&gt;# window2&lt;/span&gt;
$ python consumer.py
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512556617287&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;13&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;13&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1494513008, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512556618293&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;14&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;14&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1499251221, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;8&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512556620303&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;16&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;16&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-783427375, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;9&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512556623321&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;19&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;19&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1902514040, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512556626337&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;22&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;22&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;782849423&lt;/span&gt;, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;可以看到两个consumer同时运行的情况下，它们分别消费不同partition中的数据。window1中的consumer消费partition 0中的数据，window2中的consumer消费parition 1中的数据。&lt;/p&gt;
&lt;p&gt;我们尝试关闭window1中的consumer，可以看到如下结果&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# window2&lt;/span&gt;

ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;105&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512557514410&lt;/span&gt;,                                                                                                     &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;46&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;46&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1821060627, serialized_key_siz                                                                                                    &lt;span class="nv"&gt;e&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;106&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512557518428&lt;/span&gt;,                                                                                                     &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;50&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;50&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;281004575&lt;/span&gt;, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;                                                                                                    &lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;107&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512557521442&lt;/span&gt;,                                                                                                     &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;53&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;53&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1245067939&lt;/span&gt;, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;                                                                                                    &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;108&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512557525461&lt;/span&gt;,                                                                                                     &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;57&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;57&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1003840299, serialized_key_siz                                                                                                    &lt;span class="nv"&gt;e&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;98&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512557494325&lt;/span&gt;, t                                                                                                    &lt;span class="nv"&gt;imestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;26&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;26&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1576244323, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;                                                                                                    &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;99&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512557495329&lt;/span&gt;, t                                                                                                    &lt;span class="nv"&gt;imestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;27&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;27&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;510530536&lt;/span&gt;, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;                                                                                                    , &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;100&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512557502360&lt;/span&gt;,                                                                                                     &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;34&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;34&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1781705793&lt;/span&gt;, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;                                                                                                    &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;101&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512557504368&lt;/span&gt;,                                                                                                     &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;36&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;36&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2142677730&lt;/span&gt;, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;                                                                                                    &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;102&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512557505372&lt;/span&gt;,                                                                                                     &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;37&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;37&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1376259357, serialized_key_siz                                                                                                    &lt;span class="nv"&gt;e&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;刚开始window2中的consumer只消费partition1中的数据，当window1中的consumer退出后，window2中的consumer中也开始消费partition 0中的数据了。&lt;/p&gt;
&lt;h4&gt;实验三：offset管理&lt;/h4&gt;
&lt;p&gt;kafka允许consumer将当前消费的消息的offset提交到kafka中，这样如果consumer因异常退出后，下次启动仍然可以从上次记录的offset开始向后继续消费消息。&lt;/p&gt;
&lt;p&gt;这个实验的结构和实验一的结构是一样的，使用一个producer，一个consumer，test topic的partition数量设为1。&lt;/p&gt;
&lt;p&gt;producer的代码和实验一中的一样，这里不再重复。consumer的代码稍作修改，这里consumer中打印出下一个要被消费的消息的offset。consumer代码如下&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;kafka&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;KafkaConsumer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;TopicPartition&lt;/span&gt;

&lt;span class="n"&gt;tp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TopicPartition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;test&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;consumer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;KafkaConsumer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bootstrap_servers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;localhost:9092&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;group_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;testgoup&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;auto_offset_reset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;earliest&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enable_auto_commit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;assign&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;tp&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;starting offset is&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;position&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;message&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;message&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;在一个窗口中启动producer，在另一个窗口并且启动consumer。consumer的输出如下&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python consumer.py
start offset is &lt;span class="m"&gt;98&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;98&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512558902904&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;98&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;98&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-588818519, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;99&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512558903909&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;99&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;99&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1042712647&lt;/span&gt;, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;100&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512558904915&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;100&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;100&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-838622723, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;101&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512558905920&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;101&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;101&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-2020362485, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;102&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1512558906926&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;102&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;102&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-345378749, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;可以尝试退出consumer，再启动consumer。每一次重新启动，consumer都是从offset=98的消息开始消费的。&lt;/p&gt;
&lt;p&gt;修改consumer的代码如下，在consumer消费每一条消息后将offset提交回kafka&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;kafka&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;KafkaConsumer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;TopicPartition&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;OffsetAndMetadata&lt;/span&gt;

&lt;span class="n"&gt;tp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;TopicPartition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;test2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;consumer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;KafkaConsumer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bootstrap_servers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;localhost:9092&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;group_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;testgoup&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;auto_offset_reset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;earliest&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enable_auto_commit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;assign&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;tp&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;start offset is &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;position&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;message&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;message&lt;/span&gt;
    &lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;commit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;message&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;启动consumer&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python consumer.py
start offset is 98
ConsumerRecord(topic=u&amp;#39;test&amp;#39;, partition=0, offset=98, timestamp=1512559632153, timestamp_type=0, key=&amp;#39;824&amp;#39;, value=&amp;#39;824&amp;#39;, checksum=828849435, serialized_key_size=3, serialized_value_size=3)
...
ConsumerRecord(topic=u&amp;#39;test&amp;#39;, partition=0, offset=827, timestamp=1512559635164, timestamp_type=0, key=&amp;#39;827&amp;#39;, value=&amp;#39;827&amp;#39;, checksum=442222330, serialized_key_size=3, serialized_value_size=3)
ConsumerRecord(topic=u&amp;#39;test&amp;#39;, partition=0, offset=828, timestamp=1512559636169, timestamp_type=0, key=&amp;#39;828&amp;#39;, value=&amp;#39;828&amp;#39;, checksum=-267344764, serialized_key_size=3, serialized_value_size=3)
ConsumerRecord(topic=u&amp;#39;test&amp;#39;, partition=0, offset=829, timestamp=1512559637173, timestamp_type=0, key=&amp;#39;829&amp;#39;, value=&amp;#39;829&amp;#39;, checksum=1225853586, serialized_key_size=3, serialized_value_size=3)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;可以看到consumer从offset=98的消息开始消费，到offset=829时，我们Ctrl+C退出consumer。&lt;/p&gt;
&lt;p&gt;我们再次启动consumer&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python consumer.py
start offset is 830
ConsumerRecord(topic=u&amp;#39;test&amp;#39;, partition=0, offset=830, timestamp=1512559638177, timestamp_type=0, key=&amp;#39;830&amp;#39;, value=&amp;#39;830&amp;#39;, checksum=1003305652, serialized_key_size=3, serialized_value_size=3)
ConsumerRecord(topic=u&amp;#39;test&amp;#39;, partition=0, offset=831, timestamp=1512559639181, timestamp_type=0, key=&amp;#39;831&amp;#39;, value=&amp;#39;831&amp;#39;, checksum=-361607666, serialized_key_size=3, serialized_value_size=3)
ConsumerRecord(topic=u&amp;#39;test&amp;#39;, partition=0, offset=832, timestamp=1512559640185, timestamp_type=0, key=&amp;#39;832&amp;#39;, value=&amp;#39;832&amp;#39;, checksum=-345891932, serialized_key_size=3, serialized_value_size=3)
...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;可以看到重新启动后，consumer从上一次记录的offset开始继续消费消息。之后每一次consumer重新启动，consumer都会从上一次停止的地方继续开始消费。&lt;/p&gt;
&lt;h4&gt;总结&lt;/h4&gt;
&lt;p&gt;本文主要介绍了一下kafka的基本概念，并结合一些实验帮助理解kafka中的一些难点，如多个consumer的容错性机制，offset管理。&lt;/p&gt;
&lt;h4&gt;引用资料&lt;/h4&gt;
&lt;p&gt;kafka-python在线文档 - &lt;a href="http://link.zhihu.com/?target=http%3A//kafka-python.readthedocs.io/en/master/"&gt;kafka-python - kafka-python 1.3.6.dev documentation&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;kafka官方文档 - &lt;a href="http://link.zhihu.com/?target=https%3A//kafka.apache.org/0100/documentation.html"&gt;Apache Kafka&lt;/a&gt;&lt;/p&gt;</content><category term="misc"></category></entry><entry><title>Docker初体验</title><link href="http://www.shenzhongqiang.com/docker-intro.html" rel="alternate"></link><published>2017-11-30T00:00:00+08:00</published><updated>2017-11-30T00:00:00+08:00</updated><author><name>Zhongqiang Shen</name></author><id>tag:www.shenzhongqiang.com,2017-11-30:/docker-intro.html</id><summary type="html">&lt;p&gt;最近的项目中用到了Docker，感觉超级好用。写下这篇文章作为自己学习的一个小结，也作为一篇Docker的入门介绍。&lt;/p&gt;
&lt;p&gt;本文由以下内容组成 …&lt;/p&gt;</summary><content type="html">&lt;p&gt;最近的项目中用到了Docker，感觉超级好用。写下这篇文章作为自己学习的一个小结，也作为一篇Docker的入门介绍。&lt;/p&gt;
&lt;p&gt;本文由以下内容组成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;什么是Docker&lt;/li&gt;
&lt;li&gt;Docker基本概念&lt;/li&gt;
&lt;li&gt;容器和传统VM的区别&lt;/li&gt;
&lt;li&gt;安装Docker&lt;/li&gt;
&lt;li&gt;Docker命令简介&lt;/li&gt;
&lt;li&gt;创建Docker镜像&lt;/li&gt;
&lt;li&gt;多容器部署&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;什么是Docker&lt;/h4&gt;
&lt;p&gt;Docker用Go语言开发实现，基于Linux内核的cgroup，namespace，和AUFS类的Union FS等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。Docker 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得 Docker 技术比虚拟机技术更为轻便、快捷。&lt;/p&gt;
&lt;h4&gt;Docker基本概念&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;镜像（image）&lt;/strong&gt;- 一个独立的文件系统，类似虚拟机里的镜像，包含运行时需要的系统、软件、代码、库、环境变量、配置文件等&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;容器（container）&lt;/strong&gt;- 由镜像（image）创建的运行实例，类似虚拟机，可以对它执行启动、停止、删除等操作&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;仓库（repository）&lt;/strong&gt;- 提供集中存储、镜像分发的服务，类似github。用户可以从仓库（repository）上传或下载镜像&lt;/p&gt;
&lt;h4&gt;容器和传统VM的区别&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;传统VM架构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.shenzhongqiang.com/images/v2-7ee61067dfb9eac458ced806d2bd4fa6_r.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;容器架构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://www.shenzhongqiang.com/images/v2-f211aa72def9826fb7050944bdd5c108_r.jpg"&gt;&lt;/p&gt;
&lt;p&gt;每个虚拟机都有自己独立的操作系统，而不同的容器可以共享同一个操作系统。虚拟机面向操作系统，而Docker是面向应用的。容器一般被设计为运行一个主要进程，而不是管理多个进程集合。&lt;/p&gt;
&lt;h4&gt;安装Docker&lt;/h4&gt;
&lt;p&gt;以ubuntu为例，运行以下命令&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ apt-get install docker
$ apt-get install docker.io
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;测试docker是否安装成功，运行&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker run hello-world

Hello from Docker.
This message shows that your installation appears to be working correctly.
...
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;Docker命令简介&lt;/h4&gt;
&lt;p&gt;以busybox镜像为例&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;下载镜像&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker pull busybox
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这条命令从docker hub上下载busybox镜像存在本地&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;列出本地的镜像&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker images
REPOSITORY
busybox                                     latest              6ad733544a63        3 weeks ago         1.129 MB
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;基于镜像创建容器&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker run busybox
$
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这里没有任何输出，容器被创建后并没有运行任何命令，所以创建后就退出了&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;在容器中执行命令&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker run busybox &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;hello from busybox&amp;quot;&lt;/span&gt;
hello from busybox 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;echo命令退出，容器也随即退出。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;显示所有的容器&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker ps -a 
CONTAINER ID        IMAGE                                       COMMAND                  CREATED             STATUS                     PORTS               NAMES
0f6621b18dbe        busybox                                     &lt;span class="s2"&gt;&amp;quot;sh&amp;quot;&lt;/span&gt;                     &lt;span class="m"&gt;3&lt;/span&gt; minutes ago       Exited &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt; minutes ago                       desperate_torvalds
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;显示正在运行的容器&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker run -d busybox top &lt;span class="c1"&gt;# 启动一个容器，容器中运行top命令，这里-d表示detach模式&lt;/span&gt;
$ docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
27c2844e3a5d        busybox             &lt;span class="s2"&gt;&amp;quot;top&amp;quot;&lt;/span&gt;               &lt;span class="m"&gt;5&lt;/span&gt; minutes ago       Up &lt;span class="m"&gt;5&lt;/span&gt; minutes                            sleepy_wilson
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;在容器中运行命令&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker run -it busybox &lt;span class="c1"&gt;# -it表示连接到容器中的tty&lt;/span&gt;
/ &lt;span class="c1"&gt;# ls&lt;/span&gt;
bin   dev   etc   home  proc  root  sys   tmp   usr   var
/ &lt;span class="c1"&gt;# echo &amp;quot;hello&amp;quot;&lt;/span&gt;
hello
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;删除容器&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker rm  0f6621b18dbe
0f6621b18dbe
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;删除镜像&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker rmi busybox
Untagged: busybox:latest
Untagged: busybox@sha256:bbc3a03235220b170ba48a157dd097dd1379299370e1ed99ce976df0355d24f0
Deleted: sha256:6ad733544a6317992a6fac4eb19fe1df577d4dec7529efec28a5bd0edad0fd30
Deleted: sha256:0271b8eebde3fa9a6126b1f2335e170f902731ab4942f9f1914e77016540c7bb
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;在Docker Hub上搜索镜像&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker search busybox &lt;span class="c1"&gt;# 搜索image名字包含busybox的镜像&lt;/span&gt;
NAME                        DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED
busybox                     Busybox base image.                             &lt;span class="m"&gt;1149&lt;/span&gt;      &lt;span class="o"&gt;[&lt;/span&gt;OK&lt;span class="o"&gt;]&lt;/span&gt;
progrium/busybox                                                            &lt;span class="m"&gt;66&lt;/span&gt;                   &lt;span class="o"&gt;[&lt;/span&gt;OK&lt;span class="o"&gt;]&lt;/span&gt;
hypriot/rpi-busybox-httpd   Raspberry Pi compatible Docker Image with ...   &lt;span class="m"&gt;39&lt;/span&gt;
radial/busyboxplus          Full-chain, Internet enabled, busybox made...   &lt;span class="m"&gt;16&lt;/span&gt;                   &lt;span class="o"&gt;[&lt;/span&gt;OK&lt;span class="o"&gt;]&lt;/span&gt;
hypriot/armhf-busybox       Busybox base image &lt;span class="k"&gt;for&lt;/span&gt; ARM.                     &lt;span class="m"&gt;8&lt;/span&gt;
armhf/busybox               Busybox base image.                             &lt;span class="m"&gt;4&lt;/span&gt;
arm32v7/busybox             Busybox base image.                             &lt;span class="m"&gt;3&lt;/span&gt;
...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;检查容器中的命令输出&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker run -d busybox top &lt;span class="c1"&gt;# 启动一个容器&lt;/span&gt;
$ docker logs 10b72de4bd77 &lt;span class="c1"&gt;# 查看容器中top的输出&lt;/span&gt;
Mem: 8700192K used, 15989388K free, 247764K shrd, 299432K buff, 6261884K cached
CPU:  &lt;span class="m"&gt;0&lt;/span&gt;.0% usr  &lt;span class="m"&gt;0&lt;/span&gt;.1% sys  &lt;span class="m"&gt;0&lt;/span&gt;.0% nic &lt;span class="m"&gt;99&lt;/span&gt;.7% idle  &lt;span class="m"&gt;0&lt;/span&gt;.0% io  &lt;span class="m"&gt;0&lt;/span&gt;.0% irq  &lt;span class="m"&gt;0&lt;/span&gt;.0% sirq
Load average: &lt;span class="m"&gt;0&lt;/span&gt;.16 &lt;span class="m"&gt;0&lt;/span&gt;.09 &lt;span class="m"&gt;0&lt;/span&gt;.11 &lt;span class="m"&gt;1&lt;/span&gt;/363 &lt;span class="m"&gt;6&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;创建Docker镜像&lt;/h4&gt;
&lt;p&gt;Dockerfile可用来自动化Docker镜像的创建，它包含一系列指令来描述如何创建一个镜像。&lt;/p&gt;
&lt;p&gt;这里我们来展示如何用Dockerfile创建一个zookeeper的镜像。&lt;/p&gt;
&lt;p&gt;首先需要在Dockerfile中指定base镜像，FROM关键字用于指定base镜像。因为zookeeper要用到java，我们的镜像使用openjdk作为base&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;FROM&lt;/span&gt;&lt;span class="s"&gt; openjdk&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;MAINTAINER关键字描述镜像的创建者&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;MAINTAINER&lt;/span&gt;&lt;span class="s"&gt; Zhongqiang Shen&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;WORKDIR设置容器内的当前工作目录，如果不存在则创建目录&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;WORKDIR&lt;/span&gt;&lt;span class="s"&gt; /tmp&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;启动zookeeper服务需要从官网下载zookeeper包，撰写conf/zoo.cfg，并启动zookeeper进程。ADD关键字将URL中的内容下载到指定目录中&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;ADD&lt;/span&gt;&lt;span class="s"&gt; http://apache.osuosl.org/zookeeper/stable/zookeeper-3.4.10.tar.gz /tmp&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;RUN关键字可以在容器中运行命令。在容器中解压zookeeper包，并将加压后的包移到/opt/zookeeper位置&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;RUN&lt;/span&gt; tar -xzf zookeeper-3.4.10.tar.gz
&lt;span class="k"&gt;RUN&lt;/span&gt; mv zookeeper-3.4.10 /opt/zookeeper
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;设置zookeeper的路径为当前的工作目录&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;WORKDIR&lt;/span&gt;&lt;span class="s"&gt; /opt/zookeeper&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;撰写conf/zoo.cfg&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;RUN&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;tickTime=2000&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; conf/zoo.cfg
&lt;span class="k"&gt;RUN&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;dataDir=/var/lib/zookeeper&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; conf/zoo.cfg
&lt;span class="k"&gt;RUN&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;clientPort=2181&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; conf/zoo.cfg
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;暴露容器的2181端口，使用expose关键字&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;EXPOSE&lt;/span&gt;&lt;span class="s"&gt; 2181&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;启动zookeeper进程，使用CMD关键字。start-foreground参数让zookeeper在前台运行，如果没有这个参数，.sh脚本退出后会导致容器也退出&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;CMD&lt;/span&gt;&lt;span class="s"&gt; [&amp;quot;/opt/zookeeper/bin/zkServer.sh&amp;quot;, &amp;quot;start-foreground&amp;quot;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这里需要注意RUN和CMD的区别，RUN用于创建镜像的时候执行命令，每次执行命令都会创建新的镜像层。CMD用于指定容器启动后默认执行的命令和参数。&lt;/p&gt;
&lt;p&gt;完整的Dockerfile是这样的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;FROM&lt;/span&gt;&lt;span class="s"&gt; openjdk&lt;/span&gt;
&lt;span class="k"&gt;MAINTAINER&lt;/span&gt;&lt;span class="s"&gt; Zhongqiang Shen&lt;/span&gt;

&lt;span class="k"&gt;WORKDIR&lt;/span&gt;&lt;span class="s"&gt; /tmp&lt;/span&gt;
&lt;span class="k"&gt;ADD&lt;/span&gt;&lt;span class="s"&gt; http://apache.osuosl.org/zookeeper/stable/zookeeper-3.4.10.tar.gz /tmp&lt;/span&gt;
&lt;span class="k"&gt;RUN&lt;/span&gt; tar -xzf zookeeper-3.4.10.tar.gz
&lt;span class="k"&gt;RUN&lt;/span&gt; mv zookeeper-3.4.10 /opt/zookeeper
&lt;span class="k"&gt;WORKDIR&lt;/span&gt;&lt;span class="s"&gt; /opt/zookeeper&lt;/span&gt;
&lt;span class="k"&gt;RUN&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;tickTime=2000&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; conf/zoo.cfg
&lt;span class="k"&gt;RUN&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;dataDir=/var/lib/zookeeper&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; conf/zoo.cfg
&lt;span class="k"&gt;RUN&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;clientPort=2181&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; conf/zoo.cfg
&lt;span class="k"&gt;EXPOSE&lt;/span&gt;&lt;span class="s"&gt; 2181&lt;/span&gt;
&lt;span class="k"&gt;CMD&lt;/span&gt;&lt;span class="s"&gt; [&amp;quot;/opt/zookeeper/bin/zkServer.sh&amp;quot;, &amp;quot;start-foreground&amp;quot;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;创建完Dockerfile，就可以用下面的命令来创建镜像了&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker build -t zookeeper .
Sending build context to Docker daemon  &lt;span class="m"&gt;5&lt;/span&gt;.632kB
Step &lt;span class="m"&gt;1&lt;/span&gt;/12 : FROM openjdk
latest: Pulling from library/openjdk
3e17c6eae66c: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
fdfb54153de7: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
a4ca6e73242a: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
93bd198d0a5f: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
ca4d78fb08d6: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
ad3d1bdcab4b: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
4853d1e6d0c1: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
49e4624ad45f: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
bcbcd4c3ef93: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
Digest: sha256:b89826260c9f5ebb94ebff7ef23720f2b6de9f879df52e91afd112f53f5f7531
Status: Downloaded newer image &lt;span class="k"&gt;for&lt;/span&gt; openjdk:latest
 ---&amp;gt; 377371113dab
Step &lt;span class="m"&gt;2&lt;/span&gt;/12 : MAINTAINER zhongqiang Shen
 ---&amp;gt; Running in 03bf1c8ef563
 ---&amp;gt; 7cd7ffa57b0c
Removing intermediate container 03bf1c8ef563
Step &lt;span class="m"&gt;3&lt;/span&gt;/12 : WORKDIR /tmp
 ---&amp;gt; b180924d0413
Removing intermediate container 1461e2b93f70
Step &lt;span class="m"&gt;4&lt;/span&gt;/12 : ADD http://apache.osuosl.org/zookeeper/stable/zookeeper-3.4.10.tar.gz /tmp
Downloading &lt;span class="o"&gt;[==================================================&lt;/span&gt;&amp;gt;&lt;span class="o"&gt;]&lt;/span&gt;  &lt;span class="m"&gt;35&lt;/span&gt;.04MB/35.04MB
 ---&amp;gt; c2858e418073
Step &lt;span class="m"&gt;5&lt;/span&gt;/12 : RUN tar -xzf zookeeper-3.4.10.tar.gz
 ---&amp;gt; Running in 0cb7b253c12f
 ---&amp;gt; 0f7afb29ae74
Removing intermediate container 0cb7b253c12f
Step &lt;span class="m"&gt;6&lt;/span&gt;/12 : RUN mv zookeeper-3.4.10 /opt/zookeeper
 ---&amp;gt; Running in 68ce7228ca7e
 ---&amp;gt; 65d309c5340a
Removing intermediate container 68ce7228ca7e
Step &lt;span class="m"&gt;7&lt;/span&gt;/12 : WORKDIR /opt/zookeeper
 ---&amp;gt; b2dbec2aed3c
Removing intermediate container 8ac9df07f732
Step &lt;span class="m"&gt;8&lt;/span&gt;/12 : RUN &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;tickTime=2000&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; conf/zoo.cfg
 ---&amp;gt; Running in ef1d9dd5269a
 ---&amp;gt; 0c20dd205282
Removing intermediate container ef1d9dd5269a
Step &lt;span class="m"&gt;9&lt;/span&gt;/12 : RUN &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;dataDir=/var/lib/zookeeper&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; conf/zoo.cfg
 ---&amp;gt; Running in 7dcdb7eb07b1
 ---&amp;gt; a0a0a7341dba
Removing intermediate container 7dcdb7eb07b1
Step &lt;span class="m"&gt;10&lt;/span&gt;/12 : RUN &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;clientPort=2181&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; conf/zoo.cfg
 ---&amp;gt; Running in c2b0127e5cca
 ---&amp;gt; 6f7564eeaf4f
Removing intermediate container c2b0127e5cca
Step &lt;span class="m"&gt;11&lt;/span&gt;/12 : EXPOSE &lt;span class="m"&gt;2181&lt;/span&gt;
 ---&amp;gt; Running in cd97242108e5
 ---&amp;gt; eb91473e8a4c
Removing intermediate container cd97242108e5
Step &lt;span class="m"&gt;12&lt;/span&gt;/12 : CMD /opt/zookeeper/bin/zkServer.sh start-foreground
 ---&amp;gt; Running in 665686b5ec56
 ---&amp;gt; c4515a39ff83
Removing intermediate container 665686b5ec56
Successfully built c4515a39ff83
Successfully tagged zk:latest
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这样一个docker镜像就创建好了。可以用下面的命令来启动它&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker run zookeeper
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;多容器部署&lt;/h4&gt;
&lt;p&gt;一个应用通常由多个服务构成，将这些服务运行在容器中，就涉及到多个容器的部署。使用Docker Compose可以实现复杂的多容器应用的部署运行。&lt;/p&gt;
&lt;p&gt;Docker Compose使用docker-compose.yml来定义服务。在docker-compose.yml中，所有的容器通过services来定义。&lt;/p&gt;
&lt;p&gt;这里以kafka为例，kafka下层使用zookeeper作协调，因此这里需要定义zookeeper和kafka两个服务，先启动zookeeper，后启动kafka。&lt;/p&gt;
&lt;p&gt;首先安装Docker Compose&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ apt-get install docker-compose
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;定义docker-compose.yml，如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;version: &lt;span class="s1"&gt;&amp;#39;2&amp;#39;&lt;/span&gt;
services:
  zookeeper:
    container_name: iop-zookeeper
    image: jplock/zookeeper
    ports:
      - &lt;span class="s2"&gt;&amp;quot;2181:2181&amp;quot;&lt;/span&gt;
  kafka:
    container_name: iop-kafka
    image: wurstmeister/kafka
    environment:
      KAFKA_ZOOKEEPER_CONNECT: iop-zookeeper:2181
      KAFKA_CREATE_TOPICS: &lt;span class="s2"&gt;&amp;quot;metrics&amp;quot;&lt;/span&gt;
      KAFKA_ADVERTISED_HOST_NAME: localhost
      KAFKA_BROKER_ID: &lt;span class="m"&gt;1&lt;/span&gt;
    ports:
      - &lt;span class="s2"&gt;&amp;quot;9092:9092&amp;quot;&lt;/span&gt;
    links:
      - zookeeper
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;version指定Docker Compose的版本&lt;/p&gt;
&lt;p&gt;container_name指定容器的名字&lt;/p&gt;
&lt;p&gt;image指定使用的镜像的名字，这里使用了docker hub上现有的Dockerfile来创建zookeeper和kafka的镜像&lt;/p&gt;
&lt;p&gt;ports定义端口映射&lt;/p&gt;
&lt;p&gt;environment设置环境变量&lt;/p&gt;
&lt;p&gt;links定义容器之间的关联关系和依赖关系，这里kafka依赖于zookeeper，定义了这个依赖关系后，kafka启动前会先启动zookeeper&lt;/p&gt;
&lt;p&gt;定义了docker-compose.yml文件后，就可以通过如下命令来一键启动服务&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker-compose up -d &lt;span class="c1"&gt;# -d表示后台模式运行服务&lt;/span&gt;
Pulling zookeeper &lt;span class="o"&gt;(&lt;/span&gt;jplock/zookeeper:latest&lt;span class="o"&gt;)&lt;/span&gt;...
latest: Pulling from jplock/zookeeper
b56ae66c2937: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
81cebc5bcaf8: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
3b27fd892ecb: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
40bb2918284a: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
Digest: sha256:5fe911a016393439a963bcab2f1cc03d107816ce2c6977bfa77bfb45edef5ad0
Status: Downloaded newer image &lt;span class="k"&gt;for&lt;/span&gt; jplock/zookeeper:latest
Pulling kafka &lt;span class="o"&gt;(&lt;/span&gt;wurstmeister/kafka:latest&lt;span class="o"&gt;)&lt;/span&gt;...
latest: Pulling from wurstmeister/kafka
90f4dba627d6: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
11dbde1d93a0: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
c89218b0f06c: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
134279c08227: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
341b4d59b9c3: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
2ce0b628d981: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
82b065c991b8: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
d4f3b865c0e2: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
af829f3a4ec8: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
Digest: sha256:2aa183fd201d693e24d4d5d483b081fc2c62c198a7acb8484838328c83542c96
Status: Downloaded newer image &lt;span class="k"&gt;for&lt;/span&gt; wurstmeister/kafka:latest
Creating iop-zookeeper ...
Creating iop-zookeeper ... &lt;span class="k"&gt;done&lt;/span&gt;
Creating iop-kafka ...
Creating iop-kafka ... &lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;运行下列命令可以看到容器已启动&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker ps
CONTAINER ID        IMAGE                COMMAND                  CREATED             STATUS                             PORTS                                        NAMES
08a14f1c462a        wurstmeister/kafka   &lt;span class="s2"&gt;&amp;quot;start-kafka.sh&amp;quot;&lt;/span&gt;         &lt;span class="m"&gt;28&lt;/span&gt; seconds ago      Up &lt;span class="m"&gt;26&lt;/span&gt; seconds                      &lt;span class="m"&gt;0&lt;/span&gt;.0.0.0:9092-&amp;gt;9092/tcp                       iop-kafka
f47d27f80aac        jplock/zookeeper     &lt;span class="s2"&gt;&amp;quot;/opt/zookeeper/bi...&amp;quot;&lt;/span&gt;   &lt;span class="m"&gt;28&lt;/span&gt; seconds ago      Up &lt;span class="m"&gt;27&lt;/span&gt; seconds &lt;span class="o"&gt;(&lt;/span&gt;health: starting&lt;span class="o"&gt;)&lt;/span&gt;   &lt;span class="m"&gt;2888&lt;/span&gt;/tcp, &lt;span class="m"&gt;0&lt;/span&gt;.0.0.0:2181-&amp;gt;2181/tcp, &lt;span class="m"&gt;3888&lt;/span&gt;/tcp   iop-zookeeper
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;我们用python写个程序来测试一下启动的kafka服务&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;optparse&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;OptionParser&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;kafka&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;KafkaConsumer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;kafka&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;KafkaProducer&lt;/span&gt;

&lt;span class="n"&gt;parser&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;OptionParser&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_option&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;--action&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;store&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;choices&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;produce&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;consume&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;choice&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dest&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;action&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;options&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse_args&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;options&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;action&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;produce&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;producer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;KafkaProducer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bootstrap_servers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;localhost:9092&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;producer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;send&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;test&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="n"&gt;producer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flush&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;options&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;action&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;consume&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;consumer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;KafkaConsumer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;test&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bootstrap_servers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;localhost:9092&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;auto_offset_reset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;earliest&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;message&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;consumer&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;message&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;上面的代码包含两个功能：向kafka队列生产数据和从kafka队列消费数据。&lt;/p&gt;
&lt;p&gt;我们先向kafka队列生产数据&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python test.py --action&lt;span class="o"&gt;=&lt;/span&gt;produce
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;随后从kafka队列中消费数据，并打印出数据&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python test.py --action&lt;span class="o"&gt;=&lt;/span&gt;consume
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1511934733036&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;None, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;0&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1395146535&lt;/span&gt;, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1511934733045&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;None, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;1&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-7035501, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1511934733047&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;None, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;2&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1650992148&lt;/span&gt;, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1511934733049&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;None, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;3&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;195437617&lt;/span&gt;, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1511934733051&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;None, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;4&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1858641489, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;5&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1511934733053&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;None, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;5&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-349298306, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1511934733055&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;None, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;6&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1993515257&lt;/span&gt;, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1511934733057&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;None, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;7&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-824249467, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;8&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1511934733059&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;None, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;8&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1519664681&lt;/span&gt;, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
ConsumerRecord&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;topic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;u&lt;span class="s1"&gt;&amp;#39;test&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;partition&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;9&lt;/span&gt;, &lt;span class="nv"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1511934733061&lt;/span&gt;, &lt;span class="nv"&gt;timestamp_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;, &lt;span class="nv"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;None, &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;9&amp;#39;&lt;/span&gt;, &lt;span class="nv"&gt;checksum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;546143992&lt;/span&gt;, &lt;span class="nv"&gt;serialized_key_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1, &lt;span class="nv"&gt;serialized_value_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;可以看到之前插入的数据被成功的读取到。&lt;/p&gt;
&lt;h4&gt;总结&lt;/h4&gt;
&lt;p&gt;本文对Docker做了个简单介绍，包括Docker的基本概念、基本命令、如何创建Docker镜像、以及如何部署多容器。&lt;/p&gt;
&lt;p&gt;除以上内容，Kubernetes也是Docker生态圈中的重要一员。Kubernetes是一个开源的容器集群管理系统，提供资源调度、均衡容灾、服务注册、动态扩缩容等功能，可以作为下一步学习的内容。&lt;/p&gt;</content><category term="misc"></category></entry></feed>